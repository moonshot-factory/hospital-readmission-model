{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hospital Readmission Risk Model - Data Exploration\n",
        "\n",
        "**Project:** Hospital Readmission Risk Prediction  \n",
        "**Timeline:** January 2015 - May 2015  \n",
        "**Author:** Blake Sonnier  \n",
        "**Team:** Data Science Intern, Mentor, Clinical Advisor  \n",
        "\n",
        "## Objective\n",
        "Explore raw EHR data from Southeast Texas regional hospitals to understand:\n",
        "- Data quality issues and inconsistencies\n",
        "- Patient demographics and clinical patterns\n",
        "- Readmission patterns and potential risk factors\n",
        "- Data preprocessing requirements\n",
        "\n",
        "**Note:** This notebook demonstrates the analysis process using synthetic data that mimics the real EHR data patterns encountered during the internship."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import our custom modules\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from data_processing import EHRDataProcessor\n",
        "from visualization import ReadmissionVisualizer\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully\")\n",
        "print(f\"Analysis conducted on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Initial Assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the raw EHR dataset\n",
        "raw_data = pd.read_csv('../data/sample_data.csv')\n",
        "print(f\"Dataset loaded: {raw_data.shape}\")\n",
        "\n",
        "# Initial data inspection\n",
        "print(\"=== INITIAL DATA OVERVIEW ===\")\n",
        "print(raw_data.head())\n",
        "print(\"\\n=== DATA TYPES ===\")\n",
        "print(raw_data.dtypes)\n",
        "print(\"\\n=== BASIC STATISTICS ===\")\n",
        "print(raw_data.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Quality Assessment\n",
        "\n",
        "### Key Finding: Significant data quality issues requiring preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize data processor for quality assessment\n",
        "processor = EHRDataProcessor()\n",
        "quality_report = processor.validate_data_quality(raw_data)\n",
        "\n",
        "print(\"=== DATA QUALITY REPORT ===\")\n",
        "print(f\"Total records: {quality_report['total_records']:,}\")\n",
        "print(f\"Total columns: {quality_report['total_columns']}\")\n",
        "print(f\"Duplicates: {quality_report['duplicates']}\")\n",
        "print(f\"Issues found: {len(quality_report['issues'])}\")\n",
        "\n",
        "# Missing values analysis\n",
        "print(\"\\n=== MISSING VALUES ANALYSIS ===\")\n",
        "missing_stats = pd.DataFrame({\n",
        "    'Column': raw_data.columns,\n",
        "    'Missing_Count': raw_data.isnull().sum(),\n",
        "    'Missing_Percentage': (raw_data.isnull().sum() / len(raw_data)) * 100\n",
        "})\n",
        "missing_stats = missing_stats.sort_values('Missing_Percentage', ascending=False)\n",
        "print(missing_stats[missing_stats['Missing_Count'] > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize data quality using our custom visualizer\n",
        "visualizer = ReadmissionVisualizer()\n",
        "visualizer.plot_data_quality_overview(raw_data)\n",
        "\n",
        "# Analyze inconsistent formatting issues\n",
        "print(\"=== DATA INCONSISTENCY ANALYSIS ===\")\n",
        "\n",
        "# Gender field inconsistencies\n",
        "print(\"\\nGender field variations:\")\n",
        "print(raw_data['gender'].value_counts())\n",
        "\n",
        "# Insurance type inconsistencies\n",
        "print(\"\\nInsurance type variations:\")\n",
        "print(raw_data['insurance_type'].value_counts())\n",
        "\n",
        "# Date format issues\n",
        "print(\"\\nSample admission dates (showing format inconsistencies):\")\n",
        "print(raw_data['admission_date'].head(10).tolist())\n",
        "\n",
        "# Diagnosis codes complexity\n",
        "print(\"\\nSample diagnosis codes (showing mixed coding systems):\")\n",
        "print(raw_data['diagnosis_codes'].head(10).tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Data Analysis\n",
        "\n",
        "### Patient Demographics and Clinical Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clinical overview visualization\n",
        "visualizer.plot_clinical_overview(raw_data)\n",
        "\n",
        "# Key statistics\n",
        "print(f\"\\n=== KEY STATISTICS ===\")\n",
        "print(f\"Average age: {raw_data['age'].mean():.1f} years\")\n",
        "print(f\"Average length of stay: {raw_data['length_of_stay'].mean():.1f} days\")\n",
        "print(f\"30-day readmission rate: {(raw_data['readmission_30_day'].sum() / len(raw_data)) * 100:.1f}%\")\n",
        "print(f\"Emergency admission rate: {(raw_data['emergency_admission'].sum() / len(raw_data)) * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Risk Factor Analysis\n",
        "\n",
        "### Identifying patterns associated with readmission risk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Readmission risk by age groups\n",
        "raw_data['age_group'] = pd.cut(raw_data['age'], \n",
        "                              bins=[0, 40, 60, 80, 100], \n",
        "                              labels=['Under 40', '40-60', '60-80', 'Over 80'])\n",
        "\n",
        "risk_by_age = raw_data.groupby('age_group')['readmission_30_day'].agg(['mean', 'count']).reset_index()\n",
        "risk_by_age['readmission_rate'] = risk_by_age['mean'] * 100\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.bar(risk_by_age['age_group'].astype(str), risk_by_age['readmission_rate'])\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Readmission Rate (%)')\n",
        "plt.title('Readmission Rate by Age Group')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Risk by length of stay\n",
        "plt.subplot(2, 3, 2)\n",
        "raw_data['los_group'] = pd.cut(raw_data['length_of_stay'], \n",
        "                              bins=[0, 2, 5, 10, 100], \n",
        "                              labels=['1-2 days', '3-5 days', '6-10 days', '>10 days'])\n",
        "\n",
        "risk_by_los = raw_data.groupby('los_group')['readmission_30_day'].mean() * 100\n",
        "plt.bar(risk_by_los.index.astype(str), risk_by_los.values)\n",
        "plt.xlabel('Length of Stay')\n",
        "plt.ylabel('Readmission Rate (%)')\n",
        "plt.title('Readmission Rate by Length of Stay')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Risk by previous admissions\n",
        "plt.subplot(2, 3, 3)\n",
        "risk_by_prev = raw_data.groupby('previous_admissions')['readmission_30_day'].mean() * 100\n",
        "risk_by_prev = risk_by_prev.head(6)  # Show first 6 categories\n",
        "plt.bar(risk_by_prev.index.astype(str), risk_by_prev.values)\n",
        "plt.xlabel('Previous Admissions')\n",
        "plt.ylabel('Readmission Rate (%)')\n",
        "plt.title('Readmission Rate by Previous Admissions')\n",
        "\n",
        "# Risk by emergency admission\n",
        "plt.subplot(2, 3, 4)\n",
        "risk_by_emergency = raw_data.groupby('emergency_admission')['readmission_30_day'].mean() * 100\n",
        "emergency_labels = ['Scheduled', 'Emergency']\n",
        "plt.bar(emergency_labels, risk_by_emergency.values)\n",
        "plt.xlabel('Admission Type')\n",
        "plt.ylabel('Readmission Rate (%)')\n",
        "plt.title('Readmission Rate by Admission Type')\n",
        "\n",
        "# Correlation heatmap for numeric variables\n",
        "plt.subplot(2, 3, 5)\n",
        "numeric_cols = ['age', 'length_of_stay', 'previous_admissions', 'emergency_admission', 'readmission_30_day']\n",
        "correlation_matrix = raw_data[numeric_cols].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, square=True)\n",
        "plt.title('Feature Correlation Matrix')\n",
        "\n",
        "# Distribution of LOS for readmitted vs non-readmitted\n",
        "plt.subplot(2, 3, 6)\n",
        "readmitted = raw_data[raw_data['readmission_30_day'] == 1]['length_of_stay']\n",
        "not_readmitted = raw_data[raw_data['readmission_30_day'] == 0]['length_of_stay']\n",
        "\n",
        "plt.hist(not_readmitted, bins=20, alpha=0.7, label='Not Readmitted', density=True)\n",
        "plt.hist(readmitted, bins=20, alpha=0.7, label='Readmitted', density=True)\n",
        "plt.xlabel('Length of Stay')\n",
        "plt.ylabel('Density')\n",
        "plt.title('LOS Distribution by Readmission Status')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Medical Codes Analysis\n",
        "\n",
        "### Challenge: Multiple coding systems and translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze diagnosis codes patterns\n",
        "print(\"=== MEDICAL CODES ANALYSIS ===\")\n",
        "\n",
        "# Extract all unique codes\n",
        "all_codes = []\n",
        "for codes_string in raw_data['diagnosis_codes']:\n",
        "    if pd.notna(codes_string) and codes_string != '':\n",
        "        codes = codes_string.split(';')\n",
        "        all_codes.extend([code.strip() for code in codes if code.strip()])\n",
        "\n",
        "code_counts = pd.Series(all_codes).value_counts()\n",
        "print(f\"\\nTotal unique codes found: {len(code_counts)}\")\n",
        "print(f\"Most common codes:\")\n",
        "print(code_counts.head(15))\n",
        "\n",
        "# Identify code types\n",
        "icd9_pattern = code_counts[code_counts.index.str.contains(r'\\d{3}\\.\\d', na=False)]\n",
        "icd10_pattern = code_counts[code_counts.index.str.contains(r'[A-Z]\\d{2}\\.', na=False)]\n",
        "local_codes = code_counts[~code_counts.index.str.contains(r'\\d{3}\\.\\d|[A-Z]\\d{2}\\.', na=False)]\n",
        "\n",
        "print(f\"\\nCode system breakdown:\")\n",
        "print(f\"ICD-9 like codes: {len(icd9_pattern)}\")\n",
        "print(f\"ICD-10 like codes: {len(icd10_pattern)}\")\n",
        "print(f\"Local/Other codes: {len(local_codes)}\")\n",
        "\n",
        "# Visualize code distribution\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "code_types = ['ICD-9', 'ICD-10', 'Local/Other']\n",
        "code_type_counts = [len(icd9_pattern), len(icd10_pattern), len(local_codes)]\n",
        "plt.pie(code_type_counts, labels=code_types, autopct='%1.1f%%')\n",
        "plt.title('Distribution of Code Types')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "top_codes = code_counts.head(10)\n",
        "plt.barh(range(len(top_codes)), top_codes.values)\n",
        "plt.yticks(range(len(top_codes)), top_codes.index)\n",
        "plt.xlabel('Frequency')\n",
        "plt.title('Top 10 Most Common Codes')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Data Quality Issues Summary\n",
        "\n",
        "### Key challenges identified for preprocessing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive data quality report\n",
        "print(\"=== DATA QUALITY ISSUES SUMMARY ===\")\n",
        "print(\"\\n1. MISSING VALUES:\")\n",
        "for col in missing_stats[missing_stats['Missing_Percentage'] > 0]['Column']:\n",
        "    pct = missing_stats[missing_stats['Column'] == col]['Missing_Percentage'].iloc[0]\n",
        "    print(f\"   - {col}: {pct:.1f}% missing\")\n",
        "\n",
        "print(\"\\n2. DATA INCONSISTENCIES:\")\n",
        "print(f\"   - Gender: {len(raw_data['gender'].unique())} different formats\")\n",
        "print(f\"   - Insurance: {len(raw_data['insurance_type'].unique())} different formats\")\n",
        "print(f\"   - Date formats: Multiple inconsistent formats detected\")\n",
        "print(f\"   - Medical codes: {len(code_counts)} unique codes across 3+ systems\")\n",
        "\n",
        "print(\"\\n3. DATA OUTLIERS:\")\n",
        "outlier_los = raw_data[raw_data['length_of_stay'] > 20]\n",
        "print(f\"   - Length of stay outliers: {len(outlier_los)} patients (>20 days)\")\n",
        "\n",
        "extreme_age = raw_data[(raw_data['age'] < 18) | (raw_data['age'] > 100)]\n",
        "print(f\"   - Age outliers: {len(extreme_age)} patients (<18 or >100 years)\")\n",
        "\n",
        "print(\"\\n4. PREPROCESSING REQUIREMENTS:\")\n",
        "print(\"   ✓ Standardize gender and insurance fields\")\n",
        "print(\"   ✓ Parse and normalize date formats\")\n",
        "print(\"   ✓ Translate medical codes to common standard\")\n",
        "print(\"   ✓ Handle missing values appropriately\")\n",
        "print(\"   ✓ Detect and treat outliers\")\n",
        "print(\"   ✓ Create time-series features from admission history\")\n",
        "\n",
        "print(\"\\n=== BUSINESS INSIGHTS ===\")\n",
        "print(f\"✓ {raw_data['readmission_30_day'].mean()*100:.1f}% baseline readmission rate\")\n",
        "print(f\"✓ Emergency admissions have higher readmission risk\")\n",
        "print(f\"✓ Previous admission history is strong predictor\")\n",
        "print(f\"✓ Length of stay shows correlation with readmission\")\n",
        "print(f\"✓ Age groups show varying risk patterns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Next Steps and Recommendations\n",
        "\n",
        "Based on this exploratory analysis, the following preprocessing steps are critical:\n",
        "\n",
        "### Immediate Actions Required:\n",
        "1. **Data Standardization Pipeline**: Build robust parsers for inconsistent formats\n",
        "2. **Medical Code Translation**: Create mapping tables for ICD-9, ICD-10, and local codes\n",
        "3. **Missing Value Strategy**: Develop domain-appropriate imputation methods\n",
        "4. **Feature Engineering**: Extract meaningful patterns from temporal data\n",
        "\n",
        "### Clinical Collaboration Points:\n",
        "- **Code Mapping Validation**: Work with clinical advisor to ensure accurate translations\n",
        "- **Feature Relevance**: Validate that engineered features align with clinical understanding\n",
        "- **Risk Thresholds**: Establish clinically meaningful risk categories\n",
        "\n",
        "### Technical Implementation:\n",
        "- Pandas-based standardization functions\n",
        "- Robust date parsing with multiple format support\n",
        "- Time-series feature extraction for admission patterns\n",
        "- Quality control checks and validation rules\n",
        "\n",
        "**This analysis revealed the complexity of real-world EHR data and the critical importance of thorough data exploration before model development. The insights gained here directly informed our feature engineering and preprocessing strategies.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save data quality report for next notebook\n",
        "data_quality_report = {\n",
        "    'total_patients': len(raw_data),\n",
        "    'readmission_rate': raw_data['readmission_30_day'].mean(),\n",
        "    'missing_value_columns': missing_stats[missing_stats['Missing_Percentage'] > 0]['Column'].tolist(),\n",
        "    'unique_codes_count': len(code_counts),\n",
        "    'preprocessing_required': True\n",
        "}\n",
        "\n",
        "print(\"\\n=== EXPLORATION COMPLETE ===\")\n",
        "print(\"Data quality report prepared for feature engineering phase.\")\n",
        "print(\"\\nKey files to create next:\")\n",
        "print(\"- 02_feature_engineering.ipynb\")\n",
        "print(\"- Medical code mapping tables\")\n",
        "print(\"- Data standardization functions\")\n",
        "\n",
        "# Preview of cleaned data structure for next phase\n",
        "print(\"\\n=== PREVIEW: Target Clean Data Structure ===\")\n",
        "print(\"Columns after preprocessing:\")\n",
        "target_columns = [\n",
        "    'patient_id', 'age', 'gender_std', 'admission_date_parsed',\n",
        "    'days_since_last_admission', 'diagnosis_diabetes', 'diagnosis_hypertension',\n",
        "    'diagnosis_heart_disease', 'diagnosis_kidney_disease', 'length_of_stay',\n",
        "    'previous_admissions_imputed', 'emergency_admission', 'insurance_std',\n",
        "    'readmission_30_day'\n",
        "]\n",
        "\n",
        "for i, col in enumerate(target_columns, 1):\n",
        "    print(f\"{i:2d}. {col}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
