{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hospital Readmission Risk Model - Feature Engineering\n",
        "\n",
        "**Project:** Hospital Readmission Risk Prediction  \n",
        "**Timeline:** January 2015 - May 2015  \n",
        "**Author:** Blake Sonnier  \n",
        "\n",
        "## Objective\n",
        "Transform raw, inconsistent EHR data into standardized features suitable for machine learning:\n",
        "- Standardize inconsistent data formats\n",
        "- Translate medical codes across different systems\n",
        "- Create time-series features from admission history\n",
        "- Handle missing values appropriately\n",
        "- Engineer clinically meaningful features\n",
        "\n",
        "**Key Challenge:** Working with real EHR data required creating a robust preprocessing pipeline that could handle multiple hospital systems with different data standards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src directory to path to import our custom modules\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Import our custom modules\n",
        "from data_processing import EHRDataProcessor\n",
        "from feature_engineering import (\n",
        "    MedicalCodeTranslator, \n",
        "    TemporalFeatureEngineer, \n",
        "    ClinicalFeatureEngineer,\n",
        "    ComprehensiveFeatureEngineer\n",
        ")\n",
        "from visualization import ReadmissionVisualizer\n",
        "\n",
        "print(\"Feature engineering libraries loaded successfully\")\n",
        "print(f\"Processing started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Processed Data from Previous Step\n",
        "\n",
        "Starting with the cleaned data from the data exploration phase, or loading fresh data and processing it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the raw data (in practice, this would be the output from 01_data_exploration.ipynb)\n",
        "data_path = '../data/sample_data.csv'\n",
        "\n",
        "print(\"Loading and processing raw EHR data...\")\n",
        "raw_data = pd.read_csv(data_path)\n",
        "print(f\"Loaded raw dataset: {raw_data.shape}\")\n",
        "\n",
        "# Initialize data processor\n",
        "processor = EHRDataProcessor()\n",
        "\n",
        "# Apply basic data processing\n",
        "processed_data, processing_report = processor.process_pipeline(raw_data)\n",
        "\n",
        "print(f\"\\nData processing completed:\")\n",
        "print(f\"Original shape: {processing_report['original_shape']}\")\n",
        "print(f\"Processed shape: {processing_report['final_shape']}\")\n",
        "print(f\"Steps completed: {len(processing_report['steps_completed'])}\")\n",
        "\n",
        "# Display sample of processed data\n",
        "print(\"\\nSample of processed data:\")\n",
        "processed_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Medical Code Translation System\n",
        "\n",
        "### Challenge Solution: Unified Medical Code Mapping\n",
        "One of the biggest challenges was standardizing medical codes across different hospital systems. We created a comprehensive mapping system with clinical advisor input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize medical code translator\n",
        "translator = MedicalCodeTranslator()\n",
        "\n",
        "print(\"Medical Code Translation System\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Monitoring {len(translator.condition_mappings)} clinical conditions\")\n",
        "print(f\"Total code mappings: {len(translator.code_to_condition)}\")\n",
        "\n",
        "# Display condition mappings\n",
        "print(\"\\nConditions being tracked:\")\n",
        "for condition, mapping in translator.condition_mappings.items():\n",
        "    total_codes = sum(len(codes) for codes in mapping.values() if isinstance(codes, list))\n",
        "    print(f\"  • {condition.title()}: {total_codes} code variations\")\n",
        "\n",
        "# Example of code translation\n",
        "print(\"\\n=== EXAMPLE CODE TRANSLATIONS ===\")\n",
        "sample_codes = [\n",
        "    \"250.00;401.9\",              # ICD-9 codes\n",
        "    \"E11.9;I10;I50.9\",           # ICD-10 codes  \n",
        "    \"DM2;HTN;HF\",                # Local hospital codes\n",
        "    \"DIABETES;KIDNEY;HEART\",     # Mixed local codes\n",
        "    \"250.01;I10;COPD\"            # Mixed coding systems\n",
        "]\n",
        "\n",
        "for codes in sample_codes:\n",
        "    translated = translator.translate_codes(codes)\n",
        "    print(f\"Input: {codes}\")\n",
        "    print(f\"  → Conditions: {list(translated.keys())}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply medical code translation to our dataset\n",
        "print(\"Applying medical code translation to dataset...\")\n",
        "\n",
        "# Create condition features from diagnosis codes\n",
        "data_with_conditions = translator.create_condition_features(processed_data, 'diagnosis_codes')\n",
        "\n",
        "# Analyze condition prevalence\n",
        "condition_summary = translator.get_condition_summary(processed_data, 'diagnosis_codes')\n",
        "\n",
        "print(f\"\\nCondition Features Created:\")\n",
        "condition_cols = [col for col in data_with_conditions.columns if col.startswith('has_')]\n",
        "print(f\"Total condition features: {len(condition_cols)}\")\n",
        "\n",
        "print(f\"\\nCondition Prevalence in Dataset:\")\n",
        "for condition, stats in condition_summary.items():\n",
        "    print(f\"  • {stats['description']}: {stats['count']} patients ({stats['prevalence']*100:.1f}%)\")\n",
        "\n",
        "# Visualize condition prevalence\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "condition_prev = data_with_conditions[condition_cols].mean().sort_values(ascending=True)\n",
        "condition_names = [col.replace('has_', '').replace('_', ' ').title() for col in condition_prev.index]\n",
        "plt.barh(range(len(condition_prev)), condition_prev.values * 100)\n",
        "plt.yticks(range(len(condition_prev)), condition_names)\n",
        "plt.xlabel('Prevalence (%)')\n",
        "plt.title('Medical Conditions Prevalence')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# Comorbidity distribution\n",
        "comorbidity_count = data_with_conditions[condition_cols].sum(axis=1)\n",
        "plt.hist(comorbidity_count, bins=range(8), alpha=0.7, edgecolor='black')\n",
        "plt.xlabel('Number of Comorbidities')\n",
        "plt.ylabel('Number of Patients')\n",
        "plt.title('Comorbidity Distribution')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAverage comorbidities per patient: {comorbidity_count.mean():.1f}\")\n",
        "print(f\"Patients with multiple comorbidities (≥2): {(comorbidity_count >= 2).sum()} ({(comorbidity_count >= 2).mean()*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Temporal Feature Engineering\n",
        "\n",
        "### Creating time-series features from admission patterns\n",
        "**Challenge**: Many patients had multiple admissions, requiring time-series analysis to extract meaningful patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize temporal feature engineer\n",
        "temporal_engineer = TemporalFeatureEngineer()\n",
        "\n",
        "print(\"=== TEMPORAL FEATURE ENGINEERING ===\")\n",
        "print(\"Creating time-series features from admission patterns...\")\n",
        "\n",
        "# For demonstration, we'll simulate temporal features since our sample data\n",
        "# represents single admissions. In the real project, this would work with \n",
        "# actual admission history data.\n",
        "\n",
        "# Simulate days since last admission based on previous admissions count\n",
        "np.random.seed(42)\n",
        "def simulate_days_since_last_admission(row):\n",
        "    if row['previous_admissions'] == 0:\n",
        "        return 999  # First-time patient\n",
        "    else:\n",
        "        # Simulate realistic gaps between admissions\n",
        "        return max(1, int(np.random.exponential(90)))\n",
        "\n",
        "data_with_conditions['days_since_last_admission'] = data_with_conditions.apply(\n",
        "    simulate_days_since_last_admission, axis=1\n",
        ")\n",
        "\n",
        "# Create admission pattern features\n",
        "temporal_data = temporal_engineer.create_admission_pattern_features(\n",
        "    data_with_conditions, \n",
        "    'days_since_last_admission',\n",
        "    'previous_admissions'\n",
        ")\n",
        "\n",
        "print(f\"\\nTemporal features created:\")\n",
        "temporal_features = ['days_since_last_admission', 'recent_admission', \n",
        "                    'frequent_readmitter', 'admission_pattern']\n",
        "for feature in temporal_features:\n",
        "    if feature in temporal_data.columns:\n",
        "        print(f\"  ✓ {feature}\")\n",
        "\n",
        "# Analyze temporal patterns\n",
        "print(f\"\\n=== TEMPORAL PATTERN ANALYSIS ===\")\n",
        "\n",
        "# Recent admission analysis\n",
        "recent_rate = temporal_data['recent_admission'].mean()\n",
        "print(f\"Recent admissions (≤30 days): {recent_rate*100:.1f}%\")\n",
        "\n",
        "# Frequent readmitter analysis\n",
        "frequent_rate = temporal_data['frequent_readmitter'].mean()\n",
        "print(f\"Frequent readmitters: {frequent_rate*100:.1f}%\")\n",
        "\n",
        "# Admission pattern distribution\n",
        "pattern_dist = temporal_data['admission_pattern'].value_counts()\n",
        "print(f\"\\nAdmission pattern distribution:\")\n",
        "for pattern, count in pattern_dist.items():\n",
        "    print(f\"  • {pattern}: {count} ({count/len(temporal_data)*100:.1f}%)\")\n",
        "\n",
        "# Analyze relationship with readmissions\n",
        "if 'readmission_30_day' in temporal_data.columns:\n",
        "    print(f\"\\n=== TEMPORAL RISK ANALYSIS ===\")\n",
        "    \n",
        "    # Recent admission effect\n",
        "    recent_readmission = temporal_data.groupby('recent_admission')['readmission_30_day'].mean()\n",
        "    print(f\"Readmission rate by recent admission:\")\n",
        "    print(f\"  • Standard: {recent_readmission[0]*100:.1f}%\")\n",
        "    print(f\"  • Recent (≤30 days): {recent_readmission[1]*100:.1f}%\")\n",
        "    \n",
        "    # Frequent readmitter effect  \n",
        "    frequent_readmission = temporal_data.groupby('frequent_readmitter')['readmission_30_day'].mean()\n",
        "    print(f\"\\nReadmission rate by frequent readmitter status:\")\n",
        "    print(f\"  • Standard: {frequent_readmission[0]*100:.1f}%\")\n",
        "    print(f\"  • Frequent readmitter: {frequent_readmission[1]*100:.1f}%\")\n",
        "    \n",
        "    # Pattern-based analysis\n",
        "    pattern_readmission = temporal_data.groupby('admission_pattern')['readmission_30_day'].mean().sort_values(ascending=False)\n",
        "    print(f\"\\nReadmission rate by admission pattern:\")\n",
        "    for pattern, rate in pattern_readmission.items():\n",
        "        print(f\"  • {pattern}: {rate*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize temporal patterns\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Days since last admission distribution\n",
        "plt.subplot(2, 3, 1)\n",
        "days_subset = temporal_data[temporal_data['days_since_last_admission'] < 999]['days_since_last_admission']\n",
        "plt.hist(days_subset, bins=30, alpha=0.7, edgecolor='black')\n",
        "plt.xlabel('Days Since Last Admission')\n",
        "plt.ylabel('Number of Patients')\n",
        "plt.title('Time Between Admissions\\n(Excluding First-Time Patients)')\n",
        "plt.axvline(days_subset.mean(), color='red', linestyle='--', label=f'Mean: {days_subset.mean():.0f} days')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Recent admission by readmission status\n",
        "plt.subplot(2, 3, 2)\n",
        "if 'readmission_30_day' in temporal_data.columns:\n",
        "    recent_cross = pd.crosstab(temporal_data['recent_admission'], temporal_data['readmission_30_day'], normalize='index')\n",
        "    recent_cross.plot(kind='bar', ax=plt.gca(), color=['lightblue', 'orange'])\n",
        "    plt.xlabel('Recent Admission (≤30 days)')\n",
        "    plt.ylabel('Proportion')\n",
        "    plt.title('Recent Admission vs Readmission')\n",
        "    plt.xticks([0, 1], ['No', 'Yes'], rotation=0)\n",
        "    plt.legend(['No Readmission', 'Readmission'])\n",
        "\n",
        "# Frequent readmitter analysis\n",
        "plt.subplot(2, 3, 3)\n",
        "frequent_counts = temporal_data['frequent_readmitter'].value_counts()\n",
        "plt.pie(frequent_counts.values, labels=['Standard', 'Frequent Readmitter'], autopct='%1.1f%%')\n",
        "plt.title('Frequent Readmitter Distribution')\n",
        "\n",
        "# Admission pattern distribution\n",
        "plt.subplot(2, 3, 4)\n",
        "pattern_counts = temporal_data['admission_pattern'].value_counts()\n",
        "plt.bar(range(len(pattern_counts)), pattern_counts.values)\n",
        "plt.xticks(range(len(pattern_counts)), pattern_counts.index, rotation=45)\n",
        "plt.ylabel('Number of Patients')\n",
        "plt.title('Admission Pattern Distribution')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Risk by admission pattern\n",
        "plt.subplot(2, 3, 5)\n",
        "if 'readmission_30_day' in temporal_data.columns:\n",
        "    pattern_risk = temporal_data.groupby('admission_pattern')['readmission_30_day'].mean() * 100\n",
        "    plt.bar(range(len(pattern_risk)), pattern_risk.values)\n",
        "    plt.xticks(range(len(pattern_risk)), pattern_risk.index, rotation=45)\n",
        "    plt.ylabel('Readmission Rate (%)')\n",
        "    plt.title('Readmission Risk by Pattern')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Previous admissions vs readmission\n",
        "plt.subplot(2, 3, 6)\n",
        "if 'readmission_30_day' in temporal_data.columns:\n",
        "    prev_adm_risk = temporal_data.groupby('previous_admissions')['readmission_30_day'].mean() * 100\n",
        "    prev_adm_risk = prev_adm_risk.head(8)  # Show first 8 categories\n",
        "    plt.bar(range(len(prev_adm_risk)), prev_adm_risk.values)\n",
        "    plt.xticks(range(len(prev_adm_risk)), prev_adm_risk.index)\n",
        "    plt.xlabel('Previous Admissions')\n",
        "    plt.ylabel('Readmission Rate (%)')\n",
        "    plt.title('Risk by Admission History')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Clinical Feature Engineering\n",
        "\n",
        "### Creating features based on medical domain knowledge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize clinical feature engineer\n",
        "clinical_engineer = ClinicalFeatureEngineer()\n",
        "\n",
        "print(\"=== CLINICAL FEATURE ENGINEERING ===\")\n",
        "print(\"Creating domain-specific clinical features...\")\n",
        "\n",
        "# Step 1: Age-related features\n",
        "age_data = clinical_engineer.create_age_features(temporal_data, 'age')\n",
        "print(f\"✓ Age features created\")\n",
        "\n",
        "# Step 2: Comorbidity features\n",
        "comorbidity_data = clinical_engineer.create_comorbidity_features(age_data)\n",
        "print(f\"✓ Comorbidity features created\")\n",
        "\n",
        "# Step 3: Risk stratification\n",
        "risk_data = clinical_engineer.create_risk_stratification(comorbidity_data)\n",
        "print(f\"✓ Risk stratification features created\")\n",
        "\n",
        "# Step 4: Utilization features\n",
        "final_clinical_data = clinical_engineer.create_utilization_features(risk_data)\n",
        "print(f\"✓ Utilization features created\")\n",
        "\n",
        "# Summary of clinical features created\n",
        "clinical_features = [\n",
        "    'age_group', 'elderly', 'emergency_elderly',\n",
        "    'comorbidity_count', 'multiple_comorbidities', 'high_risk_comorbidity',\n",
        "    'clinical_risk_score', 'risk_category', 'high_risk_patient',\n",
        "    'los_category', 'long_stay', 'admission_history'\n",
        "]\n",
        "\n",
        "print(f\"\\nClinical features successfully created:\")\n",
        "for feature in clinical_features:\n",
        "    if feature in final_clinical_data.columns:\n",
        "        print(f\"  ✓ {feature}\")\n",
        "\n",
        "print(f\"\\nClinical feature summary:\")\n",
        "print(f\"  • Elderly patients (≥75): {final_clinical_data['elderly'].sum()} ({final_clinical_data['elderly'].mean()*100:.1f}%)\")\n",
        "print(f\"  • Multiple comorbidities: {final_clinical_data['multiple_comorbidities'].sum()} ({final_clinical_data['multiple_comorbidities'].mean()*100:.1f}%)\")\n",
        "print(f\"  • High-risk patients: {final_clinical_data['high_risk_patient'].sum()} ({final_clinical_data['high_risk_patient'].mean()*100:.1f}%)\")\n",
        "print(f\"  • Long stay patients: {final_clinical_data['long_stay'].sum()} ({final_clinical_data['long_stay'].mean()*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze clinical risk stratification\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Age group distribution\n",
        "plt.subplot(2, 4, 1)\n",
        "age_group_counts = final_clinical_data['age_group'].value_counts()\n",
        "plt.pie(age_group_counts.values, labels=age_group_counts.index, autopct='%1.1f%%')\n",
        "plt.title('Age Group Distribution')\n",
        "\n",
        "# Clinical risk score distribution\n",
        "plt.subplot(2, 4, 2)\n",
        "plt.hist(final_clinical_data['clinical_risk_score'], bins=20, alpha=0.7, edgecolor='black')\n",
        "plt.xlabel('Clinical Risk Score')\n",
        "plt.ylabel('Number of Patients')\n",
        "plt.title('Clinical Risk Score Distribution')\n",
        "plt.axvline(final_clinical_data['clinical_risk_score'].mean(), color='red', linestyle='--')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Risk category distribution\n",
        "plt.subplot(2, 4, 3)\n",
        "risk_cat_counts = final_clinical_data['risk_category'].value_counts()\n",
        "colors = ['green', 'yellow', 'orange', 'red']\n",
        "plt.bar(range(len(risk_cat_counts)), risk_cat_counts.values, \n",
        "        color=colors[:len(risk_cat_counts)])\n",
        "plt.xticks(range(len(risk_cat_counts)), risk_cat_counts.index, rotation=45)\n",
        "plt.ylabel('Number of Patients')\n",
        "plt.title('Risk Category Distribution')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Length of stay categories\n",
        "plt.subplot(2, 4, 4)\n",
        "los_cat_counts = final_clinical_data['los_category'].value_counts()\n",
        "plt.bar(range(len(los_cat_counts)), los_cat_counts.values)\n",
        "plt.xticks(range(len(los_cat_counts)), los_cat_counts.index)\n",
        "plt.ylabel('Number of Patients')\n",
        "plt.title('Length of Stay Categories')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Risk factors by readmission (if target available)\n",
        "if 'readmission_30_day' in final_clinical_data.columns:\n",
        "    # High-risk patient analysis\n",
        "    plt.subplot(2, 4, 5)\n",
        "    high_risk_readmission = final_clinical_data.groupby('high_risk_patient')['readmission_30_day'].mean() * 100\n",
        "    plt.bar(['Standard Risk', 'High Risk'], high_risk_readmission.values, \n",
        "            color=['lightblue', 'red'], alpha=0.7)\n",
        "    plt.ylabel('Readmission Rate (%)')\n",
        "    plt.title('Risk Classification Performance')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Elderly patient analysis\n",
        "    plt.subplot(2, 4, 6)\n",
        "    elderly_readmission = final_clinical_data.groupby('elderly')['readmission_30_day'].mean() * 100\n",
        "    plt.bar(['Non-Elderly', 'Elderly (≥75)'], elderly_readmission.values,\n",
        "            color=['lightgreen', 'orange'], alpha=0.7)\n",
        "    plt.ylabel('Readmission Rate (%)')\n",
        "    plt.title('Age Effect on Readmission')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Multiple comorbidities analysis\n",
        "    plt.subplot(2, 4, 7)\n",
        "    comorbid_readmission = final_clinical_data.groupby('multiple_comorbidities')['readmission_30_day'].mean() * 100\n",
        "    plt.bar(['Few Conditions', 'Multiple Comorbidities'], comorbid_readmission.values,\n",
        "            color=['lightblue', 'purple'], alpha=0.7)\n",
        "    plt.ylabel('Readmission Rate (%)')\n",
        "    plt.title('Comorbidity Effect')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Risk score vs readmission\n",
        "    plt.subplot(2, 4, 8)\n",
        "    # Create risk score bins\n",
        "    final_clinical_data['risk_score_bins'] = pd.cut(final_clinical_data['clinical_risk_score'], \n",
        "                                                   bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
        "    risk_bin_readmission = final_clinical_data.groupby('risk_score_bins')['readmission_30_day'].mean() * 100\n",
        "    plt.bar(range(len(risk_bin_readmission)), risk_bin_readmission.values,\n",
        "            color=plt.cm.Reds(np.linspace(0.3, 1, len(risk_bin_readmission))))\n",
        "    plt.xticks(range(len(risk_bin_readmission)), risk_bin_readmission.index, rotation=45)\n",
        "    plt.ylabel('Readmission Rate (%)')\n",
        "    plt.title('Risk Score Calibration')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print clinical insights\n",
        "if 'readmission_30_day' in final_clinical_data.columns:\n",
        "    print(f\"\\n=== CLINICAL INSIGHTS ===\")\n",
        "    print(f\"High-risk patients have {high_risk_readmission[1]/high_risk_readmission[0]:.1f}x higher readmission rate\")\n",
        "    print(f\"Elderly patients have {elderly_readmission[1]/elderly_readmission[0]:.1f}x higher readmission rate\")\n",
        "    print(f\"Multiple comorbidities increase risk by {comorbid_readmission[1]/comorbid_readmission[0]:.1f}x\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
